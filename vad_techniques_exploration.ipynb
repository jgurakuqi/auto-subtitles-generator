{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./vocals_only/test_1_vocals.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def voice_activity_detection(audio_path, threshold=0.01):\n",
    "#     # Load the audio file\n",
    "#     y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "#     # Compute the Short-Time Fourier Transform and Compute the magnitude of the STFT and Compute the root mean square (RMS) energy for each frame\n",
    "#     rms = librosa.feature.rms(\n",
    "#         S=np.abs(librosa.stft(y, n_fft=512)), frame_length=512, hop_length=128\n",
    "#     )\n",
    "\n",
    "#     # Normalize the RMS energy\n",
    "#     rms_normalized = rms / np.max(rms)\n",
    "#     del rms\n",
    "\n",
    "#     # Detect voice activity based on the threshold\n",
    "#     voice_activity = rms_normalized > threshold\n",
    "\n",
    "#     # Plot the results\n",
    "#     plt.figure(figsize=(21, 8), dpi=1000)\n",
    "#     plt.subplot(2, 1, 1)\n",
    "#     librosa.display.waveshow(y, sr=sr)\n",
    "#     plt.title(\"Waveform\")\n",
    "#     plt.subplot(2, 1, 2)\n",
    "#     plt.plot(rms_normalized[0], label=\"RMS Energy\")\n",
    "#     plt.plot(voice_activity[0], label=\"Voice Activity\", color=\"r\")\n",
    "#     plt.title(\"Voice Activity Detection\")\n",
    "#     plt.xlabel(\"Frames\")\n",
    "#     plt.ylabel(\"Normalized RMS Energy\")\n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     return voice_activity\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# audio_path = \"./vocals_only/test_1_vocals.wav\"\n",
    "# voice_activity = voice_activity_detection(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# def voice_activity_detection(audio_path, threshold=0.01, min_silence_duration=1.5):\n",
    "#     # Load the audio file\n",
    "#     y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "#     # Compute the Short-Time Fourier Transform and RMS energy\n",
    "#     rms = librosa.feature.rms(\n",
    "#         S=np.abs(librosa.stft(y, n_fft=512)), frame_length=512, hop_length=128\n",
    "#     )\n",
    "\n",
    "#     # Normalize the RMS energy\n",
    "#     rms_normalized = rms / np.max(rms)\n",
    "\n",
    "#     # Detect voice activity based on the threshold\n",
    "#     voice_activity = rms_normalized > threshold\n",
    "\n",
    "#     # Convert frame indices to time\n",
    "#     times = librosa.frames_to_time(\n",
    "#         np.arange(len(voice_activity[0])), sr=sr, hop_length=128\n",
    "#     )\n",
    "\n",
    "#     # Find intervals of voice activity\n",
    "#     intervals = []\n",
    "#     start_time = None\n",
    "#     for i, active in enumerate(voice_activity[0]):\n",
    "#         if active and start_time is None:\n",
    "#             start_time = times[i]\n",
    "#         elif not active and start_time is not None:\n",
    "#             end_time = times[i]\n",
    "#             intervals.append((start_time, end_time))\n",
    "#             start_time = None\n",
    "\n",
    "#     # Concatenate intervals with small gaps\n",
    "#     concatenated_intervals = []\n",
    "#     for start, end in intervals:\n",
    "#         if (\n",
    "#             concatenated_intervals\n",
    "#             and start - concatenated_intervals[-1][1] < min_silence_duration\n",
    "#         ):\n",
    "#             concatenated_intervals[-1] = (concatenated_intervals[-1][0], end)\n",
    "#         else:\n",
    "#             concatenated_intervals.append((start, end))\n",
    "\n",
    "#     # Prepare data for CSV\n",
    "#     data = []\n",
    "#     for start, end in concatenated_intervals:\n",
    "#         avg_energy = np.mean(\n",
    "#             rms_normalized[0][int(start * sr / 128) : int(end * sr / 128)]\n",
    "#         )\n",
    "#         data.append(\n",
    "#             {\n",
    "#                 \"Start\": librosa.time_to_frames(start, sr=sr, hop_length=128),\n",
    "#                 \"End\": librosa.time_to_frames(end, sr=sr, hop_length=128),\n",
    "#                 \"Energy\": avg_energy,\n",
    "#                 \"Threshold\": threshold,\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#     # Create a DataFrame and save to CSV\n",
    "#     df = pd.DataFrame(data)\n",
    "#     df.to_csv(\"voice_activity_intervals.csv\", index=False)\n",
    "\n",
    "#     # Plot the results\n",
    "#     plt.figure(figsize=(21, 8), dpi=1000)\n",
    "#     plt.subplot(2, 1, 1)\n",
    "#     librosa.display.waveshow(y, sr=sr)\n",
    "#     plt.title(\"Waveform\")\n",
    "#     plt.subplot(2, 1, 2)\n",
    "#     plt.plot(rms_normalized[0], label=\"RMS Energy\")\n",
    "#     plt.plot(voice_activity[0], label=\"Voice Activity\", color=\"r\")\n",
    "#     plt.title(\"Voice Activity Detection\")\n",
    "#     plt.xlabel(\"Frames\")\n",
    "#     plt.ylabel(\"Normalized RMS Energy\")\n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     return voice_activity\n",
    "\n",
    "\n",
    "# voice_activity = voice_activity_detection(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def voice_activity_detection(audio_path, threshold=0.01, min_silence_duration=1.5):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Compute the Short-Time Fourier Transform and RMS energy\n",
    "    rms = librosa.feature.rms(\n",
    "        S=np.abs(librosa.stft(y, n_fft=512)), frame_length=512, hop_length=128\n",
    "    )\n",
    "\n",
    "    # Normalize the RMS energy\n",
    "    rms_normalized = rms / np.max(rms)\n",
    "\n",
    "    # Detect voice activity based on the threshold\n",
    "    voice_activity = rms_normalized > threshold\n",
    "\n",
    "    # Convert frame indices to time\n",
    "    times = librosa.frames_to_time(\n",
    "        np.arange(len(voice_activity[0])), sr=sr, hop_length=128\n",
    "    )\n",
    "\n",
    "    # Find intervals of voice activity\n",
    "    intervals = []\n",
    "    start_time = None\n",
    "    for i, active in enumerate(voice_activity[0]):\n",
    "        if active and start_time is None:\n",
    "            start_time = times[i]\n",
    "        elif not active and start_time is not None:\n",
    "            end_time = times[i]\n",
    "            intervals.append((start_time, end_time))\n",
    "            start_time = None\n",
    "\n",
    "    # Concatenate intervals with small gaps\n",
    "    concatenated_intervals = []\n",
    "    for start, end in intervals:\n",
    "        if (\n",
    "            concatenated_intervals\n",
    "            and start - concatenated_intervals[-1][1] < min_silence_duration\n",
    "        ):\n",
    "            concatenated_intervals[-1] = (concatenated_intervals[-1][0], end)\n",
    "        else:\n",
    "            concatenated_intervals.append((start, end))\n",
    "\n",
    "    # Prepare data for CSV\n",
    "    data = []\n",
    "    for start, end in concatenated_intervals:\n",
    "        avg_energy = np.mean(\n",
    "            rms_normalized[0][int(start * sr / 128) : int(end * sr / 128)]\n",
    "        )\n",
    "        # Convert start and end times to hh:mm:ss format\n",
    "        start_hh_mm_ss = str(timedelta(seconds=int(start)))\n",
    "        end_hh_mm_ss = str(timedelta(seconds=int(end)))\n",
    "        data.append(\n",
    "            {\n",
    "                \"Start\": start_hh_mm_ss,\n",
    "                \"End\": end_hh_mm_ss,\n",
    "                \"Energy\": avg_energy,\n",
    "                \"Threshold\": threshold,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Create a DataFrame and save to CSV\n",
    "    pd.DataFrame(data).to_csv(\"voice_activity_intervals.csv\", index=False)\n",
    "\n",
    "    # # Plot the results\n",
    "    # plt.figure(figsize=(21, 8), dpi=1000)\n",
    "    # plt.subplot(2, 1, 1)\n",
    "    # librosa.display.waveshow(y, sr=sr)\n",
    "    # plt.title(\"Waveform\")\n",
    "    # plt.subplot(2, 1, 2)\n",
    "    # plt.plot(rms_normalized[0], label=\"RMS Energy\")\n",
    "    # plt.plot(voice_activity[0], label=\"Voice Activity\", color=\"r\")\n",
    "    # plt.title(\"Voice Activity Detection\")\n",
    "    # plt.xlabel(\"Frames\")\n",
    "    # plt.ylabel(\"Normalized RMS Energy\")\n",
    "    # plt.legend()\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # return voice_activity\n",
    "\n",
    "\n",
    "# voice_activity = voice_activity_detection(audio_path)\n",
    "voice_activity_detection(audio_path=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the audio file\n",
    "# y, sr = librosa.load(\n",
    "#     audio_path, sr=None, duration=300\n",
    "# )  # Load first 5 minutes (300 seconds)\n",
    "\n",
    "# # Calculate the RMS energy\n",
    "# frame_length = 512\n",
    "# hop_length = 128\n",
    "# rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "\n",
    "# # Convert RMS to decibels\n",
    "# rms_db = librosa.amplitude_to_db(rms, ref=np.max)\n",
    "\n",
    "# # Plot the RMS energy\n",
    "# plt.figure(figsize=(26, 7), dpi=800)\n",
    "# plt.plot(rms_db, label=\"RMS Energy (dB)\")\n",
    "# plt.axhline(y=-40, color=\"r\", linestyle=\"--\", label=\"Silence Threshold\")\n",
    "# plt.title(\"RMS Energy of Audio\")\n",
    "# plt.xlabel(\"Frames\")\n",
    "# plt.ylabel(\"RMS Energy (dB)\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Determine silence vs conversation\n",
    "# silence_threshold = -40  # Adjust this threshold based on your audio characteristics\n",
    "# silence_frames = rms_db < silence_threshold\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Number of silent frames: {np.sum(silence_frames)}\")\n",
    "# print(f\"Number of conversation frames: {len(silence_frames) - np.sum(silence_frames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. dB values saved to voice_activity_decibels.txt, active intervals to voice_activity_decibels_ACTIVE.txt\n"
     ]
    }
   ],
   "source": [
    "# import librosa\n",
    "# import soundfile as sf\n",
    "# import numpy as np\n",
    "# import datetime\n",
    "\n",
    "\n",
    "# def analyze_audio_decibels(\n",
    "#     audio_path, output_file, duration_limit_seconds=240\n",
    "# ):  # Limit to 4 minutes\n",
    "#     \"\"\"\n",
    "#     Analyzes an audio file, calculates the RMS decibels for each second,\n",
    "#     and stores the results in a text file.\n",
    "\n",
    "#     Args:\n",
    "#         audio_path: Path to the audio file.\n",
    "#         output_file: Path to the output text file.\n",
    "#         duration_limit_seconds: Maximum duration to analyze in seconds.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         y, sr = librosa.load(\n",
    "#             audio_path, sr=None, duration=duration_limit_seconds\n",
    "#         )  # Load with original sampling rate and apply duration limit\n",
    "#     except librosa.LibrosaError as e:\n",
    "#         print(f\"Error loading audio file: {e}\")\n",
    "#         return\n",
    "#     except sf.SoundFileError as e:\n",
    "#         print(f\"Error reading audio file: {e}\")\n",
    "#         return\n",
    "#     except Exception as e:\n",
    "#         print(f\"An unexpected error occurred: {e}\")\n",
    "#         return\n",
    "\n",
    "#     with open(output_file, \"w\") as f:\n",
    "#         f.write(\"Time - Db\\n\")  # Header\n",
    "\n",
    "#         for second in range(\n",
    "#             int(min(len(y) / sr, duration_limit_seconds))\n",
    "#         ):  # Iterate up to the duration limit or the audio length\n",
    "#             start_sample = second * sr\n",
    "#             end_sample = (second + 1) * sr\n",
    "\n",
    "#             # Ensure we don't go beyond the audio length\n",
    "#             end_sample = min(end_sample, len(y))\n",
    "\n",
    "#             if start_sample >= len(y):\n",
    "#                 break  # Exit loop if we've reached the end of the audio\n",
    "\n",
    "#             frame = y[int(start_sample) : int(end_sample)]\n",
    "\n",
    "#             if len(frame) == 0:\n",
    "#                 db = -np.inf  # If frame is empty assign -inf dB\n",
    "#             else:\n",
    "#                 rms = np.sqrt(np.mean(np.square(frame)))\n",
    "#                 if rms > 0:\n",
    "#                     db = 20 * np.log10(rms)\n",
    "#                 else:\n",
    "#                     db = -np.inf  # Handle silence to avoid log of zero\n",
    "\n",
    "#             time_str = str(datetime.timedelta(seconds=second))\n",
    "#             f.write(f\"{time_str} - Db = {db:.2f}\\n\")\n",
    "\n",
    "\n",
    "# output_text_file = \"voice_activity_decibels.txt\"\n",
    "# analyze_audio_decibels(audio_path, output_text_file)\n",
    "# print(f\"Decibel analysis complete. Results saved to {output_text_file}\")\n",
    "\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "def analyze_audio_decibels(\n",
    "    audio_path,\n",
    "    output_file_db,\n",
    "    output_file_intervals,\n",
    "    threshold_db=-40,\n",
    "    min_interval_gap=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyzes an audio file, calculates RMS decibels, stores dB values, and identifies intervals above a threshold.\n",
    "\n",
    "    Args:\n",
    "        audio_path: Path to the audio file.\n",
    "        output_file_db: Path to the output text file for decibel values.\n",
    "        output_file_intervals: Path to the output text file for intervals above threshold.\n",
    "        threshold_db: Decibel threshold for interval detection.\n",
    "        min_interval_gap: Minimum gap in seconds to consider intervals separate.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)  # Load the entire audio\n",
    "    except librosa.LibrosaError as e:\n",
    "        print(f\"Error loading audio file: {e}\")\n",
    "        return\n",
    "    except sf.SoundFileError as e:\n",
    "        print(f\"Error reading audio file: {e}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return\n",
    "\n",
    "    intervals = []\n",
    "    current_interval_start = None\n",
    "    previous_time = None\n",
    "\n",
    "    with open(output_file_db, \"w\") as f_db, open(\n",
    "        output_file_intervals, \"w\"\n",
    "    ) as f_intervals:\n",
    "        f_db.write(\"Time - Db\\n\")\n",
    "        f_intervals.write(\"Start - End\\n\")\n",
    "\n",
    "        for second in range(int(len(y) / sr)):\n",
    "            start_sample = second * sr\n",
    "            end_sample = (second + 1) * sr\n",
    "            end_sample = min(\n",
    "                end_sample, len(y)\n",
    "            )  # Ensure we don't go beyond the audio length\n",
    "            if start_sample >= len(y):\n",
    "                break  # Exit loop if we've reached the end of the audio\n",
    "            frame = y[int(start_sample) : int(end_sample)]\n",
    "\n",
    "            if len(frame) == 0:\n",
    "                db = -np.inf\n",
    "            else:\n",
    "                rms = np.sqrt(np.mean(np.square(frame)))\n",
    "                if rms > 0:\n",
    "                    db = 20 * np.log10(rms)\n",
    "                else:\n",
    "                    db = -np.inf\n",
    "\n",
    "            time_str = str(datetime.timedelta(seconds=second))\n",
    "            f_db.write(f\"{time_str} - Db = {db:.2f}\\n\")\n",
    "\n",
    "            if db > threshold_db:\n",
    "                if current_interval_start is None:\n",
    "                    current_interval_start = second\n",
    "                elif (\n",
    "                    previous_time is not None\n",
    "                    and (second - previous_time) > min_interval_gap\n",
    "                ):\n",
    "                    intervals.append((current_interval_start, previous_time))\n",
    "                    current_interval_start = second\n",
    "                previous_time = second\n",
    "            elif current_interval_start is not None:\n",
    "                intervals.append((current_interval_start, previous_time))\n",
    "                current_interval_start = None\n",
    "                previous_time = None\n",
    "        # Handle last interval if it is active\n",
    "        if current_interval_start is not None:\n",
    "            intervals.append((current_interval_start, previous_time))\n",
    "            current_interval_start = None\n",
    "            previous_time = None\n",
    "\n",
    "        for start, end in intervals:\n",
    "            start_time_str = str(datetime.timedelta(seconds=start))\n",
    "            end_time_str = str(datetime.timedelta(seconds=end))\n",
    "            f_intervals.write(f\"{start_time_str} - {end_time_str}\\n\")\n",
    "\n",
    "\n",
    "output_db_file = \"voice_activity_decibels.txt\"\n",
    "output_intervals_file = \"voice_activity_decibels_ACTIVE.txt\"\n",
    "analyze_audio_decibels(audio_path, output_db_file, output_intervals_file)\n",
    "print(\n",
    "    f\"Analysis complete. dB values saved to {output_db_file}, active intervals to {output_intervals_file}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
