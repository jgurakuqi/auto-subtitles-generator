from datetime import timedelta as datetime_timedelta
from os.path import join as os_path_join, basename as os_path_basename
from utils.utils import get_filename_with_new_extension, get_path_without_file
from numpy import load as np_load
from tqdm import tqdm
from whisperx import (
    load_align_model as whisperx_load_align_model,
    align as whisperx_align,
)

from configs.aligner_config import AlignerConfing
from utils.utils import (
    read_json,
    get_filename_with_new_extension,
    store_json,
    create_folder_if_not_exists,
    build_path,
)


def __format_time(seconds):
    """Convert seconds to SRT time format."""
    td = datetime_timedelta(seconds=seconds)
    total_seconds = int(td.total_seconds())
    hours, remainder = divmod(total_seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    milliseconds = int((td.total_seconds() - total_seconds) * 1000)
    return f"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}"


def adaptive_split_segment(
    segment,
    pause_threshold=2.0,
    duration_threshold=8.0,
    max_duration=5.0,
    sentence_marker_min_dots=2,
):
    """
    Adaptively split a segment using three steps:

    1. Split if there are long pauses between words (>= pause_threshold seconds).
    2. For segments longer than duration_threshold, split at words that contain a sentence marker,
       i.e. two or more consecutive dots.
    3. If segments are still longer than duration_threshold, split them into chunks with maximum
       duration max_duration seconds.

    Parameters:
        segment (dict): A dictionary with keys "start", "end", "text", and "words".
        pause_threshold (float): If gap between consecutive words is >= this, a split is made.
        duration_threshold (float): Only segments longer than this (in seconds) are candidates for further splitting.
        max_duration (float): Maximum allowed duration for a segment chunk in step 3.
        sentence_marker_min_dots (int): Minimum consecutive dots to consider as a sentence/split marker.

    Returns:
        list[dict]: A list of segments (each with "start", "end", "text", and "words").
                   The "text" field is re-generated by joining the "word" fields.
    """

    # Helper to create a segment from a list of word dicts.
    def create_segment(words_subset):
        if not words_subset:
            return None
        seg = {
            "start": words_subset[0]["start"],
            "end": words_subset[-1]["end"],
            "words": words_subset,
            "text": " ".join(w["word"] for w in words_subset),
        }
        return seg

    # If no words information is present, return the original segment.
    if "words" not in segment or not segment["words"]:
        return [segment]

    words = segment["words"]

    # STEP 1: Split on long pauses (>= pause_threshold seconds)
    segments_step1 = []
    start_idx = 0
    for i in range(1, len(words)):
        gap = words[i]["start"] - words[i - 1]["end"]
        if gap >= pause_threshold:
            new_seg = create_segment(words[start_idx:i])
            if new_seg is not None:
                segments_step1.append(new_seg)
            start_idx = i
    # Append the last chunk from the last pause (or whole segment if no pause)
    new_seg = create_segment(words[start_idx:])
    if new_seg is not None:
        segments_step1.append(new_seg)

    # For debugging, you might print the number of splits from step 1.
    # print(f"Step 1 produced {len(segments_step1)} segments")

    # STEP 2: For each segment from step 1 that is longer than duration_threshold,
    # split on words that contain sentence markers (".." or more).
    segments_step2 = []
    for seg in segments_step1:
        seg_duration = seg["end"] - seg["start"]
        # If not too long, just add it.
        if seg_duration <= duration_threshold:
            segments_step2.append(seg)
        else:
            words_sub = seg["words"]
            start_idx = 0
            current_segments = []
            for i, w in enumerate(words_sub):
                # Check if the word contains a sentence marker (two or more consecutive dots).
                if w["word"].count(".") >= sentence_marker_min_dots:
                    # If we are not at the beginning, consider this as a split point.
                    if i > start_idx:
                        new_seg = create_segment(words_sub[start_idx : i + 1])
                        if new_seg is not None:
                            current_segments.append(new_seg)
                        start_idx = i + 1
            # Append the remaining words if any.
            if start_idx < len(words_sub):
                new_seg = create_segment(words_sub[start_idx:])
                if new_seg is not None:
                    current_segments.append(new_seg)
            # If no splitting happened (or splitting produced empty result), keep original.
            if not current_segments:
                current_segments = [seg]
            segments_step2.extend(current_segments)

    # STEP 3: For each segment still longer than duration_threshold, split into max_duration chunks.
    segments_final = []
    for seg in segments_step2:
        seg_duration = seg["end"] - seg["start"]
        if seg_duration <= duration_threshold:
            segments_final.append(seg)
        else:
            words_sub = seg["words"]
            start_idx = 0
            current_chunks = []
            # We accumulate words until the chunk duration reaches max_duration.
            for i in range(1, len(words_sub) + 1):
                chunk_words = words_sub[start_idx:i]
                # Calculate the duration of the current chunk.
                if not chunk_words:
                    continue
                chunk_duration = chunk_words[-1]["end"] - chunk_words[0]["start"]
                if chunk_duration >= max_duration:
                    # We split here, but ensure at least one word per segment.
                    new_seg = create_segment(chunk_words)
                    if new_seg is not None:
                        current_chunks.append(new_seg)
                    start_idx = i
            # Append any remaining words.
            if start_idx < len(words_sub):
                new_seg = create_segment(words_sub[start_idx:])
                if new_seg is not None:
                    current_chunks.append(new_seg)
            # If for any reason current_chunks ended up empty, keep the original seg.
            if not current_chunks:
                current_chunks = [seg]
            segments_final.extend(current_chunks)

    return segments_final


# Example integration in the __create_srt function:
def __create_srt(segments: list[dict], audio_path: str):
    """
    Writes the given segments to an SRT file.
    Each segment is expected to have "start", "end", "text", and "words".
    The adaptive splitting is applied before writing.
    """
    output_path = os_path_join(
        get_path_without_file(audio_path),
        get_filename_with_new_extension(audio_path, "srt"),
    )
    print("Saving SRT to:", output_path)

    srt_segments = []
    for segment in segments:
        # Apply the adaptive splitting. The input segment becomes a list of segments.
        split_segs = adaptive_split_segment(
            segment,
            pause_threshold=2.0,
            duration_threshold=8.0,
            max_duration=5.0,
            sentence_marker_min_dots=2,
        )
        srt_segments.extend(split_segs)

    with open(output_path, "w") as f:
        for index, subtitle in enumerate(srt_segments, start=1):
            start_time = __format_time(subtitle["start"])
            end_time = __format_time(subtitle["end"])
            text = subtitle["text"]
            f.write(f"{index}\n{start_time} --> {end_time}\n{text}\n\n")


# import re


# def split_segment(segment, pause_threshold=2.0, max_duration=5.0, split_threshold=8.0):
#     """
#     Splits a subtitle segment using an adaptive three-step process:
#     1. Split at long pauses (â‰¥ pause_threshold seconds).
#     2. Split at stopping points (`.` or `...`) if the segment is still too long.
#     3. Split into fixed chunks of `max_duration` if necessary.

#     Parameters:
#         segment (dict): The original segment with "start", "end", "text", and "words".
#         pause_threshold (float): Minimum pause duration to trigger a split.
#         max_duration (float): Maximum length for final segment chunks.
#         split_threshold (float): Only split if the segment is longer than this.

#     Returns:
#         list[dict]: A list of processed segments.
#     """

#     segment_duration = segment["end"] - segment["start"]

#     # Step 1: Split at long pauses
#     if segment_duration > split_threshold and "words" in segment:
#         words = segment["words"]
#         new_segments = []
#         current_segment = {
#             "start": words[0]["start"],
#             "end": words[0]["end"],
#             "text": words[0]["word"],
#         }

#         for i in range(1, len(words)):
#             word = words[i]
#             prev_word = words[i - 1]
#             pause = word["start"] - prev_word["end"]

#             if pause >= pause_threshold:  # Found a long pause, create a split
#                 new_segments.append(current_segment)
#                 current_segment = {
#                     "start": word["start"],
#                     "end": word["end"],
#                     "text": word["word"],
#                 }
#             else:
#                 # Continue accumulating words in the same segment
#                 current_segment["text"] += " " + word["word"]
#                 current_segment["end"] = word["end"]

#         new_segments.append(current_segment)  # Add the last segment
#     else:
#         new_segments = [segment]  # If no split needed, return as is

#     # Step 2: Split at stopping points if still too long
#     refined_segments = []
#     for seg in new_segments:
#         if seg["end"] - seg["start"] > split_threshold:
#             split_texts = re.split(
#                 r"(\.\.\.|(?<!\w)\.)", seg["text"]
#             )  # Split on "...", or "." as standalone
#             temp_segments = []
#             temp_text = ""
#             temp_start = seg["start"]

#             word_idx = 0  # Track words from original segment
#             for i in range(
#                 0, len(split_texts), 2
#             ):  # Preserve punctuation as separate parts
#                 text_chunk = split_texts[i]
#                 if i + 1 < len(split_texts):
#                     text_chunk += split_texts[i + 1]  # Append punctuation

#                 temp_text += text_chunk.strip() + " "

#                 # Find end time of this chunk using word timestamps
#                 while (
#                     word_idx < len(seg["words"])
#                     and seg["words"][word_idx]["word"] in text_chunk
#                 ):
#                     temp_end = seg["words"][word_idx]["end"]
#                     word_idx += 1

#                 if len(temp_text) > 0:
#                     temp_segments.append(
#                         {
#                             "start": temp_start,
#                             "end": temp_end,
#                             "text": temp_text.strip(),
#                         }
#                     )
#                     temp_text = ""
#                     temp_start = temp_end  # Next segment starts from here

#             refined_segments.extend(temp_segments)
#         else:
#             refined_segments.append(seg)

#     # Step 3: If still too long, split into fixed chunks
#     final_segments = []
#     for seg in refined_segments:
#         duration = seg["end"] - seg["start"]
#         if duration > split_threshold:
#             num_splits = int(duration // max_duration)  # Number of full 5s chunks
#             remainder = duration % max_duration  # Remaining time

#             start_time = seg["start"]
#             words = seg["text"].split()
#             words_per_chunk = len(words) // (
#                 num_splits + (1 if remainder > 0 else 0)
#             )  # Roughly divide words

#             for i in range(num_splits):
#                 chunk_text = " ".join(
#                     words[i * words_per_chunk : (i + 1) * words_per_chunk]
#                 )
#                 end_time = start_time + max_duration
#                 final_segments.append(
#                     {"start": start_time, "end": end_time, "text": chunk_text}
#                 )
#                 start_time = end_time  # Move to next start time

#             # Add remainder part if exists
#             if remainder > 0:
#                 chunk_text = " ".join(words[num_splits * words_per_chunk :])
#                 final_segments.append(
#                     {"start": start_time, "end": seg["end"], "text": chunk_text}
#                 )
#         else:
#             final_segments.append(seg)

#     return final_segments


# def __create_srt(segments: list[dict[str, str | float]], audio_path: str):
#     output_path = os_path_join(
#         get_path_without_file(audio_path),
#         get_filename_with_new_extension(audio_path, "srt"),
#     )
#     print("Saving SRT to:", output_path)

#     srt_segments = []
#     for segment in segments:
#         srt_segments.extend(
#             split_segment(
#                 segment, pause_threshold=2.0, max_duration=5.0, split_threshold=8.0
#             )
#         )

#     with open(output_path, "w") as f:
#         for index, subtitle in enumerate(srt_segments, start=1):
#             start_time = __format_time(subtitle["start"])
#             end_time = __format_time(subtitle["end"])
#             text = subtitle["text"]
#             f.write(f"{index}\n{start_time} --> {end_time}\n{text}\n\n")


# def __create_srt(segments: list[dict[str, str | float]], audio_path: str):
#     output_path = os_path_join(
#         get_path_without_file(audio_path),
#         get_filename_with_new_extension(audio_path, "srt"),
#     )
#     print("utils.srt_generator.__create_srt:: Saving SRT to: ", output_path)
#     with open(output_path, "w") as f:
#         for index, subtitle in enumerate(segments, start=1):
#             start_time = __format_time(subtitle["start"])
#             end_time = __format_time(subtitle["end"])
#             text = subtitle["text"]
#             f.write(f"{index}\n{start_time} --> {end_time}\n{text}\n\n")


def generate_aligned_subtitles(
    audio_paths: list[str],
    tmp_numpy_audio_folder: str,
    tmp_intermediate_result_folder: str,
    align_model_config: AlignerConfing,
    debug_full_result_storage: bool = False,
):
    model_a, metadata = whisperx_load_align_model(
        language_code="en",
        device=align_model_config.device,
        model_dir=align_model_config.model_dir,
    )
    for audio_path in tqdm(
        audio_paths, total=len(audio_paths), desc="Generating aligned subtitles..."
    ):
        numpy_path = os_path_join(
            tmp_numpy_audio_folder,
            get_filename_with_new_extension(audio_path, "npy"),
        )
        intermediate_result_path = os_path_join(
            tmp_intermediate_result_folder,
            get_filename_with_new_extension(audio_path, "json"),
        )

        try:
            audio = np_load(numpy_path)
        except:
            print(
                "ERROR: Failed to load audio: ",
                os_path_basename(audio_path),
                "\n - Expected in path: ",
                numpy_path,
            )
            continue
        try:
            result = read_json(intermediate_result_path)
        except:
            print(
                "ERROR: Failed to load intermediate result: ",
                os_path_basename(audio_path),
                "\n - Expected in path: ",
                intermediate_result_path,
            )
            continue

        result = whisperx_align(
            transcript=result["segments"],
            model=model_a,
            align_model_metadata=metadata,
            audio=audio,
            device=align_model_config.device,
            return_char_alignments=False,
            print_progress=align_model_config.print_progress,
        )

        if debug_full_result_storage:
            # Create debug folder if it doesn't exist
            create_folder_if_not_exists("./debug_full_result/")

            debug_path = build_path(
                folder_path="./debug_full_result/",
                file_path=audio_path,
                extension_replacement="json",
            )

            store_json(
                data=result,
                output_path=debug_path,
            )

        __create_srt(
            audio_path=audio_path,
            segments=[
                {
                    "start": curr_segment["start"],
                    "end": curr_segment["end"],
                    "text": curr_segment["text"],
                }
                for curr_segment in result["segments"]
            ],
        )
